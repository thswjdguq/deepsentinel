from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict
import uvicorn
import time
import random
import os
from dotenv import load_dotenv
from openai import OpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

app = FastAPI(
    title="DeepSentinel AI Server",
    description="ë”¥í˜ì´í¬ íƒì§€ AI ë¶„ì„ ì„œë²„",
    version="2.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class AnalysisMetrics(BaseModel):
    """
    ë¶„ì„ ìˆ˜ì¹˜ ëª¨ë¸
    """
    eye_blink_rate: float  # ëˆˆ ê¹œë¹¡ì„ ë¹ˆë„ (0-100)
    lip_sync_score: float  # ì…ìˆ  ë™ê¸°í™” ì ìˆ˜ (0-100)
    lighting_consistency: float  # ë¹›ì˜ ì¼ê´€ì„± (0-100)
    facial_artifacts: float  # ì–¼êµ´ ì¸ê³µë¬¼ ì§€ìˆ˜ (0-100)
    texture_quality: float  # í…ìŠ¤ì²˜ í’ˆì§ˆ (0-100)
    motion_smoothness: float  # ë™ì‘ ë¶€ë“œëŸ¬ì›€ (0-100)


class AnalysisResponse(BaseModel):
    """
    ë¶„ì„ ê²°ê³¼ ì‘ë‹µ ëª¨ë¸
    """
    result: str  # 'real', 'fake', 'uncertain'
    confidence: float  # ì‹ ë¢°ë„ (0-1)
    metrics: AnalysisMetrics
    report: str  # GPT ìƒì„± ë¦¬í¬íŠ¸
    analysis_time: float  # ë¶„ì„ ì†Œìš” ì‹œê°„ (ì´ˆ)


def generate_analysis_metrics() -> AnalysisMetrics:
    """
    ë”¥í˜ì´í¬ ë¶„ì„ì„ ìœ„í•œ ì„ì˜ì˜ ë©”íŠ¸ë¦­ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì¶œë ¥ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.
    
    Returns:
        AnalysisMetrics: ìƒì„±ëœ ë¶„ì„ ìˆ˜ì¹˜
    """
    # ì§„ì§œ/ê°€ì§œë¥¼ ê²°ì •í•˜ëŠ” ëœë¤ ì‹œë“œ
    is_fake = random.random() < 0.4  # 40% í™•ë¥ ë¡œ ë”¥í˜ì´í¬
    
    if is_fake:
        # ë”¥í˜ì´í¬ì¼ ê²½ìš°: ë¹„ì •ìƒì ì¸ ìˆ˜ì¹˜
        metrics = AnalysisMetrics(
            eye_blink_rate=random.uniform(15, 35),  # ë¹„ì •ìƒì ìœ¼ë¡œ ë‚®ìŒ
            lip_sync_score=random.uniform(50, 75),  # ë™ê¸°í™” ë¬¸ì œ
            lighting_consistency=random.uniform(40, 70),  # ë¹›ì˜ ë¶ˆì¼ì¹˜
            facial_artifacts=random.uniform(60, 90),  # ë†’ì€ ì¸ê³µë¬¼
            texture_quality=random.uniform(45, 70),  # ë‚®ì€ í…ìŠ¤ì²˜ í’ˆì§ˆ
            motion_smoothness=random.uniform(50, 75),  # ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë™ì‘
        )
    else:
        # ì§„ì§œì¼ ê²½ìš°: ì •ìƒ ìˆ˜ì¹˜
        metrics = AnalysisMetrics(
            eye_blink_rate=random.uniform(65, 95),  # ìì—°ìŠ¤ëŸ¬ìš´ ëˆˆ ê¹œë¹¡ì„
            lip_sync_score=random.uniform(80, 98),  # ì™„ë²½í•œ ë™ê¸°í™”
            lighting_consistency=random.uniform(75, 95),  # ì¼ê´€ëœ ë¹›
            facial_artifacts=random.uniform(5, 25),  # ë‚®ì€ ì¸ê³µë¬¼
            texture_quality=random.uniform(80, 95),  # ë†’ì€ í…ìŠ¤ì²˜ í’ˆì§ˆ
            motion_smoothness=random.uniform(85, 98),  # ìì—°ìŠ¤ëŸ¬ìš´ ë™ì‘
        )
    
    return metrics


def calculate_overall_score(metrics: AnalysisMetrics) -> tuple[str, float]:
    """
    ë©”íŠ¸ë¦­ì„ ê¸°ë°˜ìœ¼ë¡œ ì „ì²´ ì ìˆ˜ì™€ ê²°ê³¼ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        metrics: ë¶„ì„ ë©”íŠ¸ë¦­
        
    Returns:
        tuple: (result, confidence) - ê²°ê³¼ì™€ ì‹ ë¢°ë„
    """
    # ê°€ì¤‘ì¹˜ ì ìš© ì ìˆ˜ ê³„ì‚°
    score = (
        metrics.eye_blink_rate * 0.15 +
        metrics.lip_sync_score * 0.25 +
        metrics.lighting_consistency * 0.20 +
        (100 - metrics.facial_artifacts) * 0.25 +
        metrics.texture_quality * 0.10 +
        metrics.motion_smoothness * 0.05
    )
    
    # ê²°ê³¼ íŒì •
    if score >= 75:
        result = "real"
        confidence = min(score / 100, 0.95)
    elif score >= 50:
        result = "uncertain"
        confidence = 0.5 + (score - 50) / 100
    else:
        result = "fake"
        confidence = min((100 - score) / 100, 0.95)
    
    return result, confidence


async def generate_gpt_report(
    metrics: AnalysisMetrics,
    result: str,
    confidence: float
) -> str:
    """
    OpenAI GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ ì „ë¬¸ì ì¸ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        metrics: ë¶„ì„ ë©”íŠ¸ë¦­
        result: ë¶„ì„ ê²°ê³¼ ('real', 'fake', 'uncertain')
        confidence: ì‹ ë¢°ë„ (0-1)
        
    Returns:
        str: ìƒì„±ëœ ë¦¬í¬íŠ¸
    """
    # ê²°ê³¼ë³„ ë ˆì´ë¸”
    result_labels = {
        "real": "ì•ˆì „",
        "fake": "ìœ„í—˜",
        "uncertain": "ì£¼ì˜"
    }
    
    # GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ì‚¬ì´ë²„ ìˆ˜ì‚¬ëŒ€ì˜ ë”¥í˜ì´í¬ ë²•ì˜í•™ ì „ë¬¸ê°€ì•¼.

ë‹¤ìŒ ì˜ìƒ ë¶„ì„ ìˆ˜ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ ê°ì • ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜:

[ë¶„ì„ ìˆ˜ì¹˜]
- ëˆˆ ê¹œë¹¡ì„ ìì—°ë„: {metrics.eye_blink_rate:.1f}/100
- ìŒì„±-ì…ìˆ  ë™ê¸°í™”: {metrics.lip_sync_score:.1f}/100
- ì¡°ëª… ì¼ê´€ì„±: {metrics.lighting_consistency:.1f}/100
- ì–¼êµ´ ì¸ê³µë¬¼ ì§€ìˆ˜: {metrics.facial_artifacts:.1f}/100
- í…ìŠ¤ì²˜ í’ˆì§ˆ: {metrics.texture_quality:.1f}/100
- ë™ì‘ ë¶€ë“œëŸ¬ì›€: {metrics.motion_smoothness:.1f}/100

[ì¢…í•© íŒì •]
- ìƒíƒœ: {result_labels[result]}
- ì‹ ë¢°ë„: {confidence*100:.1f}%

# ì§€ì¹¨:
1. 3~4ë¬¸ì¥ ì´ë‚´ë¡œ ì‘ì„±
2. ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ë˜ ì´í•´í•˜ê¸° ì‰½ê²Œ
3. ì£¼ìš” ê·¼ê±°ë¥¼ ëª…í™•íˆ ì œì‹œ
4. "ì´ ì˜ìƒì€ [{result_labels[result]}] ìƒíƒœì´ë©°..."ë¡œ ì‹œì‘
5. ì¡´ëŒ“ë§ ì‚¬ìš©
6. ë²•ì˜í•™ì  ê°ê´€ì„± ìœ ì§€

ê°ì • ë³´ê³ ì„œ:"""

    try:
        # OpenAI API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì‚¬ì´ë²„ ìˆ˜ì‚¬ëŒ€ì˜ ë”¥í˜ì´í¬ ê°ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  ì „ë¬¸ì ì¸ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.7,
            max_tokens=300
        )
        
        report = response.choices[0].message.content.strip()
        return report
        
    except Exception as e:
        # OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¦¬í¬íŠ¸ ë°˜í™˜
        print(f"OpenAI API Error: {e}")
        return f"ì´ ì˜ìƒì€ [{result_labels[result]}] ìƒíƒœì´ë©°, ë¶„ì„ ì‹ ë¢°ë„ëŠ” {confidence*100:.1f}%ì…ë‹ˆë‹¤. ì£¼ìš” ë¶„ì„ ì§€í‘œë¡œëŠ” ì…ìˆ  ë™ê¸°í™”({metrics.lip_sync_score:.1f}ì ), ì¡°ëª… ì¼ê´€ì„±({metrics.lighting_consistency:.1f}ì ), ì–¼êµ´ ì¸ê³µë¬¼ ì§€ìˆ˜({metrics.facial_artifacts:.1f}ì )ê°€ ì¢…í•©ì ìœ¼ë¡œ ê²€í† ë˜ì—ˆìŠµë‹ˆë‹¤."


@app.get("/")
async def root():
    """
    ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ - API ì •ë³´ ì œê³µ
    """
    return {
        "service": "DeepSentinel AI Server",
        "version": "2.0.0",
        "status": "running",
        "features": ["deepfake_detection", "gpt_report_generation"]
    }


@app.get("/api/health")
async def health_check():
    """
    í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
    """
    openai_status = "configured" if os.getenv("OPENAI_API_KEY") else "not_configured"
    
    return {
        "status": "healthy",
        "timestamp": time.time(),
        "openai": openai_status
    }


@app.post("/api/analyze", response_model=AnalysisResponse)
async def analyze_video(video: UploadFile = File(...)):
    """
    ì˜ìƒ ë”¥í˜ì´í¬ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸
    
    Args:
        video: ë¶„ì„í•  ì˜ìƒ íŒŒì¼
        
    Returns:
        AnalysisResponse: ë¶„ì„ ê²°ê³¼ ë° GPT ë¦¬í¬íŠ¸
    """
    start_time = time.time()
    
    try:
        # íŒŒì¼ íƒ€ì… ê²€ì¦
        if not video.content_type or not video.content_type.startswith("video/"):
            raise HTTPException(
                status_code=400,
                detail="Invalid file type. Only video files are supported."
            )
        
        # ì„ì‹œ íŒŒì¼ ì½ê¸° (ì‹¤ì œ ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜)
        contents = await video.read()
        file_size_mb = len(contents) / (1024 * 1024)
        
        print(f"ğŸ“¹ Analyzing video: {video.filename} ({file_size_mb:.2f} MB)")
        
        # ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜ (ì§§ì€ ëŒ€ê¸°)
        await asyncio.sleep(0.5)
        
        # 1. ë©”íŠ¸ë¦­ ìƒì„±
        metrics = generate_analysis_metrics()
        
        # 2. ì¢…í•© ì ìˆ˜ ê³„ì‚°
        result, confidence = calculate_overall_score(metrics)
        
        # 3. GPT ë¦¬í¬íŠ¸ ìƒì„±
        report = await generate_gpt_report(metrics, result, confidence)
        
        # ë¶„ì„ ì†Œìš” ì‹œê°„
        analysis_time = time.time() - start_time
        
        print(f"âœ… Analysis complete: {result} (confidence: {confidence:.2%})")
        
        return AnalysisResponse(
            result=result,
            confidence=confidence,
            metrics=metrics,
            report=report,
            analysis_time=analysis_time
        )
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Analysis error: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Analysis failed: {str(e)}"
        )


# asyncio import ì¶”ê°€
import asyncio


if __name__ == "__main__":
    port = int(os.getenv("AI_SERVER_PORT", 8000))
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=port,
        reload=True
    )
